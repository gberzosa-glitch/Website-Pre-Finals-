<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title></title>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
<link rel="stylesheet" href="Assets/styles.css">
</head>
<body>
<nav class="navbar navbar-expand-lg bg-body-tertiary">
  <div class="container-fluid">
    <a class="navbar-brand" href="#"></a>
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
        <li class="nav-item">
          <a class="nav-link active" aria-current="page" href="ethics.html">Information about Ethics</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="faq.html">GenAI FAQs</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="article.html">Article</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="index.html">Homepage</a>
        </li>
    </div>
  </div>
</nav>

<h1 class="text-center">Ethical Use of AI</h1>
<h2 class="text-center">What is AI Ethics?</h2>
<p class="text-center">AI ethics are the set of guiding principles that stakeholders (from engineers to government officials) use to ensure artificial intelligence technology is developed and used responsibly. This means taking a safe, secure, humane, and environmentally friendly approach to AI. A strong AI code of ethics can include avoiding bias, ensuring privacy of users and their data, and mitigating environmental risks. Codes of ethics in companies and government regulation frameworks are two main ways that AI ethics can be implemented. By covering global and national ethical AI issues, and laying the policy groundwork for ethical AI in companies, both approaches help regulate AI technology. More broadly, the discussion around AI ethics has progressed from being centered around academic research and non-profit organizations. Today, big tech companies like IBM, Google, and Meta have assembled teams to tackle ethical issues that arise from collecting massive amounts of data. At the same time, government and intergovernmental entities have begun to devise regulations and ethics policy based on academic research.</p>
<h2 class="text-center">Why It Matters?</h2>
<p class="text-center">AI ethics are important because AI technology is meant to augment or replace human intelligence—but when technology is designed to replicate human life, the same issues that can cloud human judgment can seep into the technology. AI projects built on biased or inaccurate data can have harmful consequences, particularly for underrepresented or marginalized groups and individuals. Further, if AI algorithms and machine learning models are built too hastily, then it can become unmanageable for engineers and product managers to correct learned biases. It's easier to incorporate a code of ethics during the development process to mitigate any future risks.</p>
<h3 class="text-center">Example of AI Issues</h3>
<p class="text-center">It may be easiest to illustrate the ethics of artificial intelligence with real-life examples. In December 2022, the app Lensa AI used artificial intelligence to generate cool, cartoon-looking profile photos from people’s regular images. From an ethical standpoint, some people criticized the app for not giving credit or enough money to artists who created the original digital art on which the AI was trained [1]. According to The Washington Post, Lensa was being trained on billions of photographs sourced from the internet without consent. Another example is the AI model ChatGPT, which enables users to produce original content by asking questions. ChatGPT is trained on data from the internet and can answer a question in a variety of ways, whether it be a poem, Python code, or a proposal. One ethical dilemma is that people are using ChatGPT to win coding contests or write essays. It also raises similar questions to Lensa, but with text rather than images. These are just two popular examples of AI ethics. As AI has grown in recent years, influencing nearly every industry and having a huge positive impact on industries like health care, the topic of AI ethics has become even more salient. How do we ensure bias-free AI? What can be done to mitigate risks in the future? There are many potential solutions, but stakeholders must act responsibly and collaboratively to ensure positive outcomes across the globe.</p>
<h2 class="text-center">How to Create More Ethical AI</h2>
<p class="text-center">Creating more ethical AI requires a close look at the ethical implications of policy, education, and technology. Regulatory frameworks can ensure that technologies benefit society rather than harm it. Globally, governments are beginning to enforce policies for ethical AI, including how companies should deal with legal issues if bias or other harm arises. Anyone who encounters AI should understand the risks and potential negative impact of AI that is unethical or fake. The creation and dissemination of accessible resources can mitigate these types of risks. It may seem counterintuitive to use technology to detect unethical behavior in other forms of technology, but AI tools can be used to determine whether video, audio, or text is fake or not. These tools can detect unethical data sources and biases better and more efficiently than humans.</p>

<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>
<script src="script.js"></script>
</body>
</html>